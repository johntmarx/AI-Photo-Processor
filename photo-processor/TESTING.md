# AI Photo Processor - Comprehensive Test Suite ğŸ§ª

This directory contains a complete test suite with near 100% coverage for the AI Photo Processing pipeline.

## Test Structure

```
tests/
â”œâ”€â”€ unit/                          # Unit tests for individual components
â”‚   â”œâ”€â”€ test_ai_analyzer.py       # AI analyzer module tests (40+ test cases)
â”‚   â”œâ”€â”€ test_image_processor.py   # Image processing tests (35+ test cases)
â”‚   â”œâ”€â”€ test_immich_client.py     # Immich API client tests (30+ test cases)
â”‚   â””â”€â”€ test_schemas.py           # Data validation tests (50+ test cases)
â”œâ”€â”€ integration/                   # Integration tests
â”‚   â””â”€â”€ test_photo_processor_service.py  # End-to-end workflow tests
â”œâ”€â”€ fixtures/                     # Test data and mocks
â”‚   â””â”€â”€ mock_data.py              # Mock objects and test data generators
â””â”€â”€ conftest.py                   # Pytest configuration and shared fixtures
```

## Test Coverage Areas

### ğŸ¤– AI Analyzer Tests (`test_ai_analyzer.py`)
- âœ… Ollama client connection and model availability
- âœ… Photo analysis with structured outputs  
- âœ… JSON parsing and Pydantic validation
- âœ… Error handling for network failures
- âœ… Model response format handling (dict vs object)
- âœ… Temperature and prompt configuration
- âœ… Filename inclusion in analysis prompts

### ğŸ–¼ï¸ Image Processor Tests (`test_image_processor.py`)
- âœ… RAW image loading (ARW, CR2, NEF, etc.)
- âœ… Image resizing for AI analysis
- âœ… Smart cropping with bounding boxes
- âœ… Color enhancement (brightness, contrast, CLAHE)
- âœ… Auto white balance correction
- âœ… Image saving with quality control
- âœ… Complete processing workflows
- âœ… Error handling for file operations

### ğŸŒ Immich Client Tests (`test_immich_client.py`)
- âœ… API connection and authentication
- âœ… Album creation and management
- âœ… Photo upload with metadata
- âœ… AI-generated descriptions
- âœ… Asset addition to albums
- âœ… Error handling for API failures
- âœ… Request timeout configuration
- âœ… File handling and multipart uploads

### ğŸ“‹ Schema Tests (`test_schemas.py`)
- âœ… Pydantic model validation
- âœ… Bounding box coordinate validation
- âœ… Crop suggestion parameters
- âœ… Color analysis data structures
- âœ… Swimming context validation
- âœ… Complete photo analysis schema
- âœ… JSON serialization/deserialization
- âœ… Field validation and constraints

### ğŸ”„ Integration Tests (`test_photo_processor_service.py`)
- âœ… End-to-end file processing workflow
- âœ… Service startup and health checks
- âœ… File watching and stability checks
- âœ… Error handling across components
- âœ… Concurrent processing capabilities
- âœ… Album integration
- âœ… Quality-based processing decisions

## Running Tests

### Install Test Dependencies
```bash
# Install test requirements
pip install -r test-requirements.txt

# Or use the test runner
./run_tests.py install
```

### Run All Tests
```bash
# Run complete test suite with coverage
./run_tests.py all

# Run without coverage
./run_tests.py all --no-coverage
```

### Run Specific Test Types
```bash
# Unit tests only
./run_tests.py unit

# Integration tests only  
./run_tests.py integration

# Schema validation tests
./run_tests.py schema

# Code quality check
./run_tests.py lint
```

### Run Specific Tests
```bash
# Run specific test file
./run_tests.py specific --path tests/unit/test_ai_analyzer.py

# Run specific test function
./run_tests.py specific --path tests/unit/test_ai_analyzer.py::TestAIAnalyzer::test_analyze_photo_success
```

### Run Tests by Markers
```bash
# Run only unit tests
./run_tests.py markers --markers unit

# Run tests that require external services
./run_tests.py markers --markers requires_ollama requires_immich

# Run slow tests
./run_tests.py markers --markers slow
```

## Test Configuration

### Pytest Configuration (`pytest.ini`)
- ğŸ“Š Coverage reporting (HTML, XML, terminal)
- ğŸ¯ 90% coverage requirement
- â±ï¸ Test timeouts and duration reporting
- ğŸ·ï¸ Custom markers for test categorization
- ğŸ“ Comprehensive logging

### Test Fixtures (`conftest.py`)
- ğŸ—‚ï¸ Temporary directory management
- ğŸ–¼ï¸ Mock image data generation
- ğŸ¤– Service mocking (Ollama, Immich)
- ğŸ”§ Environment variable setup
- ğŸ“Š Logging configuration

### Mock Data (`fixtures/mock_data.py`)
- ğŸŠ Swimming photo analysis samples
- ğŸ–¼ï¸ Image array generators
- ğŸ“¡ API response mocks
- ğŸ“ Test file generators
- ğŸ§° Testing utilities

## Coverage Goals

Our test suite aims for **â‰¥90% code coverage** across all modules:

| Module | Target Coverage | Test Count |
|--------|----------------|------------|
| `ai_analyzer.py` | 95%+ | 40+ tests |
| `image_processor.py` | 95%+ | 35+ tests |
| `immich_client.py` | 95%+ | 30+ tests |
| `schemas.py` | 98%+ | 50+ tests |
| `main.py` | 90%+ | 20+ tests |

## Test Data

The test suite uses the **10 real ARW files** copied to `/home/john/immich/photo-processor/test-data/`:
- DSC09497.ARW (67MB)
- DSC09501.ARW (67MB) 
- DSC09509.ARW (66MB)
- DSC09528.ARW (66MB)
- DSC09531.ARW (66MB)
- DSC09535.ARW (66MB)
- DSC09544.ARW (66MB)
- DSC09557.ARW (67MB)
- DSC09580.ARW (68MB)
- DSC09585.ARW (66MB)

These provide realistic test data for RAW image processing validation.

## Test Execution Examples

### Basic Test Run
```bash
# Quick unit test run
./run_tests.py unit -v

# Full test suite with verbose output
./run_tests.py all -v
```

### Coverage Analysis
```bash
# Generate coverage report
./run_tests.py coverage

# View HTML coverage report
open htmlcov/index.html
```

### CI/CD Integration
```bash
# Silent run for automated testing
python -m pytest --quiet --cov=. --cov-fail-under=90

# XML output for CI systems
python -m pytest --cov=. --cov-report=xml --junit-xml=test-results.xml
```

## Test Philosophy

This test suite follows these principles:

1. **Comprehensive Coverage**: Every function, method, and code path is tested
2. **Realistic Scenarios**: Tests use real-world data and edge cases
3. **Fast Execution**: Unit tests run in milliseconds, full suite in seconds
4. **Isolated Testing**: Each test is independent and can run in any order
5. **Clear Assertions**: Every test has specific, meaningful assertions
6. **Error Simulation**: Network failures, file errors, and edge cases are tested
7. **Documentation**: Tests serve as living documentation of expected behavior

## Troubleshooting

### Common Issues

**ImportError**: Make sure all dependencies are installed:
```bash
pip install -r test-requirements.txt
```

**Coverage Too Low**: Check which lines aren't covered:
```bash
./run_tests.py all -v
open htmlcov/index.html
```

**Test Failures**: Run specific failing tests with verbose output:
```bash
./run_tests.py specific --path tests/unit/test_ai_analyzer.py -v
```

### Environment Setup

For the tests to run properly, ensure:
- âœ… Python 3.11+ is installed
- âœ… All test dependencies are available
- âœ… Test data files exist (for integration tests)
- âœ… No conflicting processes on test ports

The test suite is designed to be **self-contained** and **mock all external dependencies**, so it can run without Ollama, Immich, or GPU access.

---

ğŸ¯ **Goal**: Achieve and maintain **â‰¥95% test coverage** with **comprehensive error handling** and **realistic test scenarios** to ensure the AI photo processing pipeline works reliably in production.